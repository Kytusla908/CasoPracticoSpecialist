{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of a Pre-Trained Model (RoBERTa)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
=======
   "execution_count": 1,
>>>>>>> origin/main
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\julia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, Trainer, TrainingArguments, pipeline\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Data and Training"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": 3,
>>>>>>> origin/main
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
<<<<<<< HEAD
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\julia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\accelerate\\accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
=======
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
>>>>>>> origin/main
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
<<<<<<< HEAD
       "model_id": "7b372e70c5a0469a94f98e4b8b0fcd8a",
=======
       "model_id": "8bc0c1c38194413f8dd30e8cc8324157",
>>>>>>> origin/main
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
<<<<<<< HEAD
       "  0%|          | 0/390 [00:00<?, ?it/s]"
=======
       "  0%|          | 0/780 [00:00<?, ?it/s]"
>>>>>>> origin/main
      ]
     },
     "metadata": {},
     "output_type": "display_data"
<<<<<<< HEAD
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 12041.3618, 'train_samples_per_second': 0.517, 'train_steps_per_second': 0.032, 'train_loss': 0.648263432429387, 'epoch': 3.0}\n"
     ]
=======
>>>>>>> origin/main
    }
   ],
   "source": [
    "df = pd.read_csv('ML_Models/Propietary_Models/token_datasets.csv')\n",
    "\n",
    "# String Conversion\n",
    "df['Posts'] = df['Posts'].astype(str)\n",
    "\n",
    "# Label Mapping\n",
    "label_mapping = {'Positive': 0, 'Depression/Suicidal Thoughts': 1, 'Neutral': 2}\n",
    "df['label'] = df['label'].map(label_mapping)\n",
    "\n",
    "# Load pre-trained RoBERTa model and tokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base', clean_up_tokenization_spaces=True)\n",
    "model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=3)\n",
    "\n",
<<<<<<< HEAD
    "# Move model to GPU if available\n",
    "if torch.cuda.is_available():\n",
    "    model = model.to('cuda')\n",
    "\n",
=======
    "# Preprocess Data\n",
>>>>>>> origin/main
    "# Tokenize the input texts\n",
    "inputs = tokenizer(list(df['Posts']), padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "# Get labels\n",
    "labels = torch.tensor(df['label'].values, dtype=torch.long)\n",
    "\n",
    "# Create a PyTorch Dataset\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx].clone().detach() for key, val in self.encodings.items()}\n",
    "        item['labels'] = self.labels[idx].clone().detach()\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "dataset = CustomDataset(inputs, labels)\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
<<<<<<< HEAD
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    fp16=True,\n",
=======
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    eval_strategy=\"epoch\",\n",
>>>>>>> origin/main
    ")\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "try:\n",
    "    trainer.train()\n",
    "except Exception as e:\n",
    "    print(\"Error during training:\", e)\n"
   ]
<<<<<<< HEAD
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split dataset into training and validation\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(df['Posts'], df['label'], test_size=0.2)\n",
    "\n",
    "# Tokenize validation set\n",
    "val_inputs = tokenizer(list(val_texts), padding=True, truncation=True, return_tensors='pt')\n",
    "val_labels = torch.tensor(val_labels.values, dtype=torch.long)\n",
    "\n",
    "# Create validation dataset\n",
    "val_dataset = CustomDataset(val_inputs, val_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\julia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\accelerate\\accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9c6d3bbeaed494b8cf2fb619040b911",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results: {'eval_loss': 0.23036621510982513, 'eval_model_preparation_time': 0.006, 'eval_accuracy': 0.908433734939759, 'eval_f1': 0.9093068745570517, 'eval_precision': 0.9168163046523811, 'eval_recall': 0.908433734939759, 'eval_runtime': 464.3046, 'eval_samples_per_second': 0.894, 'eval_steps_per_second': 0.056}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def compute_metrics(p):\n",
    "    preds = np.argmax(p.predictions, axis=1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(p.label_ids, preds, average='weighted')\n",
    "    acc = accuracy_score(p.label_ids, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    "\n",
    ")\n",
    "\n",
    "eval_results = trainer.evaluate()\n",
    "print(\"Evaluation results:\", eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1d228b2775d46d0ba0f6e635470fd3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              precision    recall  f1-score   support\n",
      "\n",
      "                    Positive       0.98      0.74      0.84        57\n",
      "Depression/Suicidal Thoughts       0.73      0.86      0.79        78\n",
      "                     Neutral       0.96      0.96      0.96       280\n",
      "\n",
      "                    accuracy                           0.91       415\n",
      "                   macro avg       0.89      0.85      0.86       415\n",
      "                weighted avg       0.92      0.91      0.91       415\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Get predictions from the model\n",
    "preds_output = trainer.predict(val_dataset)\n",
    "preds = np.argmax(preds_output.predictions, axis=1)\n",
    "\n",
    "# Generate the classification report\n",
    "print(classification_report(val_labels, preds, target_names=['Positive', 'Depression/Suicidal Thoughts', 'Neutral']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saved the trained model and tokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./sentiment_analysis_model\\\\tokenizer_config.json',\n",
       " './sentiment_analysis_model\\\\special_tokens_map.json',\n",
       " './sentiment_analysis_model\\\\vocab.json',\n",
       " './sentiment_analysis_model\\\\merges.txt',\n",
       " './sentiment_analysis_model\\\\added_tokens.json')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained('./sentiment_analysis_model')\n",
    "tokenizer.save_pretrained('./sentiment_analysis_model')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the Model: Making a simple prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: I am feeling great today!\n",
      "Predicted label: Neutral\n",
      "\n",
      "Text: I feel very depressed and hopeless.\n",
      "Predicted label: Depression/Suicidal Thoughts\n",
      "\n",
      "Text: This is a neutral statement.\n",
      "Predicted label: Neutral\n",
      "\n",
      "Text: Nice try. I am dying slow and painfully\n",
      "Predicted label: Neutral\n",
      "\n",
      "Text: I hate my birthday not just because I wish it never happened. But also because, even if I set up a party. No one would be there.\n",
      "Predicted label: Neutral\n",
      "\n",
      "Text: I'm happy\n",
      "Predicted label: Positive\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaForSequenceClassification, RobertaTokenizer\n",
    "import torch\n",
    "\n",
    "# Load the saved model and tokenizer\n",
    "model = RobertaForSequenceClassification.from_pretrained('sentiment_analysis_model')\n",
    "tokenizer = RobertaTokenizer.from_pretrained('sentiment_analysis_model')\n",
    "\n",
    "# List of input texts\n",
    "texts = [\n",
    "    \"I am feeling great today!\",\n",
    "    \"I feel very depressed and hopeless.\",\n",
    "    \"This is a neutral statement.\",\n",
    "    \"Nice try. I am dying slow and painfully\",\n",
    "    \"I hate my birthday not just because I wish it never happened. But also because, even if I set up a party. No one would be there.\",\n",
    "    \"I'm happy\",\n",
    "]  \n",
    "\n",
    "# Tokenize the input texts\n",
    "inputs = tokenizer(texts, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "# Determine the device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Move the model to the appropriate device\n",
    "model = model.to(device)\n",
    "\n",
    "# Move the input tensors to the same device as the model\n",
    "inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "\n",
    "# Make predictions\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "\n",
    "# Get predicted classes (indices of the highest logits)\n",
    "predicted_classes = torch.argmax(logits, dim=1).tolist()\n",
    "\n",
    "# Define label mapping\n",
    "label_mapping = {0: 'Positive', 1: 'Depression/Suicidal Thoughts', 2: 'Neutral'}\n",
    "\n",
    "# Get the predicted labels\n",
    "predicted_labels = [label_mapping[predicted_class] for predicted_class in predicted_classes]\n",
    "\n",
    "# Print results\n",
    "for text, label in zip(texts, predicted_labels):\n",
    "    print(f\"Text: {text}\\nPredicted label: {label}\\n\")\n",
    "\n"
   ]
=======
>>>>>>> origin/main
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
